# 技術知識盤點

## 何謂文本摘要

將文本萃取出重點簡短段落的紀錄

## 分類

根據 input 不同：
- 單文檔摘要：從單一文章萃取
- 多文檔摘要：從多篇文章生成

根據 output 不同：
- 抽取式摘要：由原文檔中抽取關鍵詞、關鍵句組成
  - 優點：語法上錯誤率較低
  - 缺點：選句錯誤、語意連貫性差、靈活性低
- 生成式摘要：根據原文檔生成新的詞語短句組成摘要
  - 優點：靈活性高
  - 缺點：語意問題

## 摘要质量的评估方法

### 人工評估

**金字塔方法(pyramid method)**
- m位专家撰写参考摘要，然后人工分析每个参考摘要，提取摘要内容单元(summary content unit, SCU)（表示摘要中子句级的重要语义单元）的集合，并为参考摘要中每个SCU赋值，被w个参考摘要提及则赋值为w。
- 然后计算所有SCU在系统摘要中的得分之和，系统摘要得分与理想摘要得分的比值作为质量评价得分。

### 自動評估

**ROUGE 指標**
- Recall-Oriented Understudy for Gisting Evaluation
- 用來評估文本摘要、機器翻譯的指標
- 衡量自動生成摘要與參考摘要（答案）之間的相似度
- 将待审摘要和参考摘要的n元组共现统计量作为评价依据
- 分類
  - ROUGH-N、ROUGH-L、ROUGH-W、ROUGH-S和ROUGH-SU几个类型

**BLEU 指標**
- 1-gram 精确率表示译文忠于原文的程度，而其他 n-gram 表示翻译的流畅程度


BLEU v.s. ROUGE
- BLEU 计算主要基于精确率——通順問題
  - 常用於傳統統計翻譯方法 SMT 的評估
- ROUGE 是基於召回率——漏翻問題
  - 不評估是否通順，只適用表現較好的神經網絡 NMT  

## 抽取式摘要
由原文檔中抽取關鍵詞、關鍵句組成，因此語法上錯誤率較低（不重新構句）

- 基于统计：统计词频、位置、长度、是否包含标题词等信息，计算句子的得分，再选出得分高的句子作为摘要。例如 Lead-3 等。特点：简单易用，但对词句的使用大多仅停留在表面信息
- 基於特徵：例如 TextTeaser
- 基于图模型：将句子看作结点，句子之间的相似度看作边，构建图，然后用PageRank算法迭代得到每个句子的得分。例如 TextRank, LexRank 等
- 基于潜在语义：使用主题模型，挖掘语句的隐藏信息。例如 LDA, HMM
- 基于线路规划：将摘要问题转为线路规划，求全局最优解
- 基于有監督机器学习：句子分类（摘要句、非摘要句，可视为序列标注问题）、聚类（每个类选择一个距离质心最近的句子）等。例如 SummaRuNNer 算法
- 基於有監督深度學習：例如 BertSum
- 基於中心度：例如 Centroid Bow 算法
- 基於信息冗余：例如 MMR 算法


### 基於 MMR 的摘要抽取
- Maximum Margin Relevance 最大边缘相关
  - 是一種常见的最小化冗余度算法
- 針對相似度做懲罰，使得模型找出「與已選句子最相關但最不相似的句子」加入摘要集合

### TextTeaser 算法
- 根据词频、位置、长度、是否包含标题词等统计指标，计算句子的得分，再选出得分高的句子作为摘要。

### TextRank 算法
- 将句子看作结点，句子之间的相似度看作边，构建图，然后用类似PageRank的算法迭代得到每个句子的得分，最终将得分高的句子输出得到摘要。

### 可读性问题
- 因为各个句子都是从不同的段落中选择出来的，如果只是生硬地连起来生成摘要的话，很难保证句子之间的衔接和连贯
- 取巧解法是保持原本上下文順序輸出

### 基於神經網絡方法

- 以「序列標注任務」建模
- 以「句子排序任務」建模

#### 以「序列標注任務」建模

當成監督式學習- NLP 序列標注問題處理，對每個句子打一個 0 / 1 的二元分類標籤，標記是否要選為摘要中的句子

問題：缺乏這類的句子標籤

可能的解法：
- 通過啟發式規則獲取：???
  - 具体方法为：首先选取原文中与标准摘要计算 ROUGE 得分最高的一句话加入候选集合，接着继续从原文中进行选择，保证选出的摘要集合 ROUGE 得分增加，直至无法满足该条件。得到的候选摘要集合对应的句子设为 1 标签，其余为 0 标签

#### 序列標註結合 Seq2Seq
同前者，在序列標註的基礎上結合 Seq2Seq 和強化學習，其中
- Seq2Seq 用來衡量句子選擇的好壞

問題：
- 缺乏這類的句子標籤
- 就算使用了句子標籤來訓練，也會缺失很多標準摘要(?)的重要資訊

解法：
- Latent 模型不采用序列标注方法计算标签级别的损失来训练模型，而是将序列标注作为中间的步骤。
- 在得到序列标注的概率分布之后，从中采样候选摘要集合，与标准摘要对比计算损失，可以更好地利用标准摘要中的信息

##### （句子標籤的生成方式）

- 直接標註
- 以是否包含某關鍵詞為考量

#### 以「句子排序任務」建模

针对每个句子输出其是否是摘要句的概率，最终依据概率，选取 top k 个句子作为最终摘要。

問題：
- 之前的模型都是在得到句子的表示以后对于句子进行打分，这就造成了打分与选择是分离的，先打分，后根据得分进行选择。没有利用到句子之间的关系

解法：
- 使用文章收益分為訓練目標，考慮到最終集合的句子組成不同直接影響收益，同時修正對各個句子的打分
- 其中 r 代表 ROUGE 评价指标，代表已经选择的句子集合，代表候选句子，目标是使得 g 越大越好，即选择最大化收益的句子。

## 生成式摘要

通过理解原文的意思来生成摘要，允許包含新詞、句子，靈活性較抽取式高。趨同於翻譯任務和對話任務，從而可以吸收、借鑑翻譯任務和對話任務的成功經驗。Seq2Seq 被廣泛應用在此任務上。

常見做法
- 早期 LSTM
- 基于 Encoder-Decoder 的生成式摘要 (基於深度學習、更常見)
  - 在语义向量空间内对文本进行编码，然后通过解码网络逐词生成摘要。例如 Seq2Seq, lstm2lstm
- 基於注意力機制
  - Seq2Seq + Attention 
- 基於自注意力機制
  - Self-Attention, Transformer
- 預訓練 + 微調
  - PreSumm, BertSum
- 基于信息融合的生成式摘要
  - 例如基于句法分析树的信息融合技术，利用句法结构树定义概念和事实，计算概念和事实的重要性，度量概念和事实的兼容性，最终组合概念和事实形成摘要句子

### 基於 Seq2Seq 框架

問題：
- 未登錄詞 (OOV)
- 摘要不通順
- 摘要重复性
- 长文本摘要生成难度大
- 模型的训练目标与最终的评测指标不太一致

#### ACL17 - Pointer Generator 指针生成网络 - 在 Seq2Seq 基礎上增加 Copy & Coverage 機制

- 使用每一步解码的隐层状态与编码器的隐层状态计算权重，最终得到 context 向量，利用 context 向量和解码器隐层状态计算输出概率。
- 利用 Copy 机制，需要在解码的每一步计算拷贝或生成的概率，因为词表是固定的，该机制可以选择从原文中拷贝词语到摘要中，有效的缓解了未登录词（OOV）的问题
- 利用 Coverage 机制，需要在解码的每一步考虑之前步的 attention 权重，结合 coverage 损失， 避免继续考虑已经获得高权重的部分。该机制可以有效缓解生成重复的问题

#### ICLR18 
- 使用解码器注意力机制结合强化学习

#### EMNLP18
- 基于句子级别的注意力机制，使用句子级别的 Coverage 来使得不同的摘要句可以关注不同的原文，缓解了生成信息重复的问题

### 生成对抗方式

#### AAAI18

SeqGAN

利用生成模型 G 生成摘要，利用判別模型 D 區分真實摘要 v.s. 生成摘要；再使用强化学习的方法，更新参数。

## 抽取＋生成摘要

内容选择部分建模为词语级别序列标注任务，该部分的训练数据通过将摘要对齐到文档，得到词语级别的标签。
摘要生成部分使用 pointer-generator 网络，使用内容选择部分计算的概率修改原本 attention 概率，使得解码器仅关注选择的内容。

## Reference

- [NLP-文本摘要：“文本摘要”综述（Text Summarization）](https://blog.csdn.net/u013250861/article/details/119972657)
- [【关于 文本摘要】 那些你不知道的事](https://github.com/km1994/NLP-Interview-Notes/tree/main/NLPinterview/summary)
- [文本摘要(text summarization)一:語料簡介概述綜述與工具](https://www.twblogs.net/a/5eedb5b70b72ce4a1580cbf2)